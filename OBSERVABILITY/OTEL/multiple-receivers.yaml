kind: Namespace
apiVersion: v1
metadata:
  name: otel-o11y
  labels:
    security.openshift.io/scc.podSecurityLabelSync: "false"
    pod-security.kubernetes.io/enforce: "privileged"
    pod-security.kubernetes.io/audit: "privileged"
    pod-security.kubernetes.io/warn: "privileged"  
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otel
  namespace: otel-o11y
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: otel-collector
  namespace: otel-o11y
rules:
- apiGroups:
  - "events.k8s.io"
  resources:
  - events
  verbs:
  - watch
  - list
- apiGroups:
  - quota.openshift.io
  resources:
  - clusterresourcequotas
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - events
  - namespaces
  - namespaces/status
  - nodes
  - nodes/spec
  - nodes/stats
  - nodes/proxy
  - pods
  - pods/status
  - replicationcontrollers
  - replicationcontrollers/status
  - resourcequotas
  - services
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - apps
  resources:
  - daemonsets
  - deployments
  - replicasets
  - statefulsets
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - extensions
  resources:
  - daemonsets
  - deployments
  - replicasets
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - batch
  resources:
  - jobs
  - cronjobs
  verbs:
  - get
  - list
  - watch
- apiGroups:
    - autoscaling
  resources:
    - horizontalpodautoscalers
  verbs:
    - get
    - list
    - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: otel-crb
roleRef:
  kind: ClusterRole
  name: otel-collector
  apiGroup: rbac.authorization.k8s.io 
subjects:
  - kind: ServiceAccount
    name: otel
    namespace: otel-o11y
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: otel-jounald-crb
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:openshift:scc:privileged
subjects:
- kind: ServiceAccount
  name: otel
  namespace: otel-o11y 
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: otel-monitoring-view
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-monitoring-view
subjects:
  - kind: ServiceAccount
    name: otel
    namespace: otel-o11y
---
apiVersion: security.openshift.io/v1
kind: SecurityContextConstraints
metadata:
  name: otel-scc
users:
- system:serviceaccount:otel-o11y:otel

allowHostDirVolumePlugin: true
allowHostIPC: false
allowHostNetwork: false
allowHostPID: true
allowHostPorts: false
allowPrivilegeEscalation: true
allowPrivilegedContainer: true
allowedCapabilities: null
defaultAddCapabilities:
- SYS_ADMIN
fsGroup:
  type: RunAsAny
groups: []
readOnlyRootFilesystem: true
runAsUser:
  type: RunAsAny
seLinuxContext:
  type: RunAsAny
supplementalGroups:
  type: RunAsAny
volumes:
- configMap
- emptyDir
- hostPath
- projected
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: cabundle
  namespace: otel-o11y
  annotations:
    service.beta.openshift.io/inject-cabundle: "true"
---
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: otel
  namespace: otel-o11y
spec:
  serviceAccount: otel
  mode: daemonset  
  securityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
      - CHOWN
      - DAC_OVERRIDE
      - FOWNER
      - FSETID
      - KILL
      - NET_BIND_SERVICE
      - SETGID
      - SETPCAP
      - SETUID
    readOnlyRootFilesystem: true
    seLinuxOptions:
      type: spc_t
    seccompProfile:
      type: RuntimeDefault  
  volumeMounts:
    - name: cabundle-volume
      mountPath: /etc/pki/ca-trust/source/service-ca
      readOnly: true
    - mountPath: /hostfs
      name: host
      readOnly: true      
    - name: journal-logs
      mountPath: /var/log/journal/
      readOnly: true      
  volumes:
    - name: cabundle-volume
      configMap:
        name: cabundle
    - hostPath:
        path: /
      name: host     
    - name: journal-logs
      hostPath:
        path: /var/log/journal         
  config:
    receivers:
      hostmetrics:
        collection_interval: 60s
        initial_delay: 1s
        root_path: /
        scrapers: 
          cpu: {}
          memory: {}
          disk: {}
# cpu, disk, load, filesystem, memory, network, paging, processes, and process          
      k8sobjects:
        auth_type: serviceAccount
        objects:
          - name: pods
            mode: pull 
            interval: 60s
          - name: events
            mode: watch
      kubeletstats:
        collection_interval: 60s
        auth_type: "serviceAccount"
        endpoint: "https://${env:K8S_NODE_NAME}:10250"
        insecure_skip_verify: true
      k8s_cluster:
        distribution: openshift
        collection_interval: 60s        
      journald:
        files: /var/log/journal/*/*
        priority: info 
        units:
          - kubelet
          - crio
          - init.scope
          - dnsmasq
        all: true
        retry_on_failure:
          enabled: true
          initial_interval: 1s
          max_interval: 60s
          max_elapsed_time: 5m
      k8s_events:
        #namespaces: [project1, project2]
    exporters:
      debug:
        verbosity: detailed
#      otlp:
#        endpoint: <otlp-endpoint>:4317
#        tls:
#          ca_file: ca.pem
#          cert_file: cert.pem
#          key_file: key.pem
#          insecure: false
#          insecure_skip_verify: false
#        headers:
#          X-Scope-OrgID: "dev"

    service:
      pipelines:
        metrics:
          receivers:
            - hostmetrics
            - kubeletstats
            - k8s_cluster
          processors: []
          exporters:
            - debug
            #- otlp
        logs:
          receivers:
            - k8sobjects
            - journald
            - k8s_events
          processors: []
          exporters:
            - debug   
            #- otlp
        logs/entity_events:
          receivers:
            - k8s_cluster
          processors: []
          exporters:
            - debug    
            #- otlp       
  env:
    - name: K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
